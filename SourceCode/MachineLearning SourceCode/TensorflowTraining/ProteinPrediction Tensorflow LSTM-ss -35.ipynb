{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edward\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Edward\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Edward\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Edward\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Edward\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Edward\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Edward\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Edward\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Edward\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Edward\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Edward\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Edward\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete without error\n"
     ]
    }
   ],
   "source": [
    "##Author: Wong Yuk Ming, Edward\n",
    "##Remarks: it seems using keras does not require us to convert numpy array to tensor, it will done once we fit the data\n",
    "#References:\n",
    "#https://www.dlology.com/blog/how-to-choose-last-layer-activation-and-loss-function/\n",
    "import os \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy import load\n",
    "\n",
    "#loading the file from desire directory\n",
    "path = \"../itasserSx9\" ##<-modify this directory is ok\n",
    "\n",
    "filenames= os.listdir(path)\n",
    "x_List=[]\n",
    "y_List=[]\n",
    "xyfileTuple=[]\n",
    "\n",
    "#since on linux file are not ordered by name, there is no way to guarentee n+1 file is the y file of x file n\n",
    "#there will not be any selection that limit the number of file to process\n",
    "\n",
    "for names in filenames:\n",
    "    if names.endswith(\"-x-.npy\"):\n",
    "        x_List.append(names)\n",
    "    else:\n",
    "        y_List.append(names)\n",
    "\n",
    "##testing purpose\n",
    "#print(x_List)\n",
    "#print(y_List)\n",
    "\n",
    "for xfile in x_List:\n",
    "    for yfile in y_List:\n",
    "        if (xfile.replace('-x-.npy','') == yfile.replace('-y-.npy','')):\n",
    "            xyfileTuple.append((xfile,yfile))\n",
    "            break\n",
    "##testing purpose\n",
    "#print(xyfileTuple)\n",
    "\n",
    "#notice that this cell has no error\n",
    "print('complete without error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "complete without error\n"
     ]
    }
   ],
   "source": [
    "#from filename convert to numpy array \n",
    "##input:  array of tuple contains x file name and y file name, purpose <\"angle\", \"nonangle\">\n",
    "##output: array of tuple contains x numpy array and y numpy array\n",
    "def extractData(tupleToConv, purpose):\n",
    "    outputTensorTuple=[]\n",
    "    i=0\n",
    "    for pair in tupleToConv:\n",
    "        if(purpose=='angle'):\n",
    "            xdatanp=load(path+\"/\"+pair[0])\n",
    "            #xdatatf=tf.convert_to_tensor(xdatanp, dtype=np.float32)\n",
    "            ydatanp=load(path+\"/\"+pair[1])\n",
    "            #print(ydatanp)\n",
    "            ydatanp=ydatanp[:,4:6]\n",
    "            #if(i==0):\n",
    "                #print('from y')\n",
    "                #print(ydatanp)\n",
    "            #ydatatf=tf.convert_to_tensor(xdatanp, dtype=np.float32)\n",
    "            outputTensorTuple.append((xdatanp,ydatanp))\n",
    "            \n",
    "        else:\n",
    "            xdatanp=load(path+\"/\"+pair[0])\n",
    "            #xdatatf=tf.convert_to_tensor(xdatanp, dtype=np.float32)\n",
    "            \n",
    "            ydatanp=load(path+\"/\"+pair[1])\n",
    "            ydatanp=ydatanp[:,:4]\n",
    "            if(i==0):\n",
    "                print(ydatanp)\n",
    "            #ydatatf=tf.convert_to_tensor(xdatanp, dtype=np.float32)\n",
    "            outputTensorTuple.append((xdatanp,ydatanp))\n",
    "        \n",
    "        i=i+1\n",
    "            \n",
    "    return outputTensorTuple\n",
    "\n",
    "angleAllData = extractData(xyfileTuple,purpose='angle')\n",
    "ssAllData = extractData(xyfileTuple,purpose='nonangle')\n",
    "\n",
    "#notice that this cell has no error\n",
    "print('complete without error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete without error\n"
     ]
    }
   ],
   "source": [
    "#extract to k-mers where k=18 for each amino acid position\n",
    "#for amino acid at position n, x= n-18:n, y=ny\n",
    "#also add padding\n",
    "\n",
    "\n",
    "angleKmersData=[]\n",
    "ssKmersData=[]\n",
    "\n",
    "#specify how many file want to process in here\n",
    "numFileProcess=100 ##<-modify this for changing -1 = process all file\n",
    "if (numFileProcess==-1):\n",
    "    numFilProcess=len(angleAllData)\n",
    "\n",
    "for i in range(numFileProcess):\n",
    "    thisAngleTuple = angleAllData[i]\n",
    "    thisSSTuple = ssAllData[i]\n",
    "    #orgAngleLenght=thisAngleTuple[0].shape[0]\n",
    "    #orgSSLenght=thisSSTuple[0].shape[0]\n",
    "    thisAngleTuple=(np.insert(thisAngleTuple[0],0,np.zeros((17,9)),axis=0),thisAngleTuple[1])\n",
    "    thisSSTuple=(np.insert(thisSSTuple[0],0,np.zeros((17,9)),axis=0),thisSSTuple[1])\n",
    "    thisAngleTuple=(np.append(thisAngleTuple[0],np.zeros((17,9)),axis=0),thisAngleTuple[1])\n",
    "    thisSSTuple=(np.append(thisSSTuple[0],np.zeros((17,9)),axis=0),thisSSTuple[1])\n",
    "    for j in range(thisAngleTuple[1].shape[0]):\n",
    "        x_vec=None\n",
    "        y_vec=None\n",
    "        x_vec=thisAngleTuple[0][j:j+35,:]\n",
    "        y_vec=thisAngleTuple[1][j,:]\n",
    "        angleKmersData.append((x_vec,y_vec))\n",
    "\n",
    "    for j in range(thisSSTuple[1].shape[0]):\n",
    "        x_vec=None\n",
    "        y_vec=None    \n",
    "        x_vec=thisSSTuple[0][j:j+35,:]\n",
    "        y_vec=thisSSTuple[1][j,:]\n",
    "        ssKmersData.append((x_vec,y_vec))\n",
    "       \n",
    "'''\n",
    "for i in range(numFileProcess):\n",
    "    thisAngleTuple = angleAllData[i]\n",
    "    thisSSTuple = ssAllData[i]\n",
    "    ##reporter\n",
    "    #if(i==0):\n",
    "        #print(thisAngleTuple[0].shape)\n",
    "        #print(thisAngleTuple[0][0:18,:])\n",
    "    for j in range(thisAngleTuple[0].shape[0]):\n",
    "        x_vec=None\n",
    "        y_vec=None\n",
    "        if(j<18):\n",
    "            #print(j)\n",
    "            x_vec=thisAngleTuple[0][0:j+1,:]\n",
    "            x_vec=np.insert(x_vec, 0 , np.zeros([17-j,9]) , axis=0)#adding padding\n",
    "            #print(x_vec)\n",
    "            #print(x_vec.shape)\n",
    "        else:\n",
    "            #print(j)\n",
    "            x_vec=thisAngleTuple[0][j-17:j+1,:]\n",
    "            #if(j==18):\n",
    "            #    print(x_vec)\n",
    "            #print(x_vec.shape)\n",
    "        y_vec=thisAngleTuple[1][j,:]\n",
    "        #x_vec=tf.convert_to_tensor(x_vec, dtype=np.float32)\n",
    "        #y_vec=tf.convert_to_tensor(y_vec, dtype=np.float32)\n",
    "        angleKmersData.append((x_vec,y_vec))\n",
    "    for j in range(thisAngleTuple[0].shape[0]):\n",
    "        x_vec=None\n",
    "        y_vec=None\n",
    "        if(j<18):\n",
    "            #print(j)\n",
    "            x_vec=thisSSTuple[0][0:j+1,:]\n",
    "            x_vec=np.insert(x_vec, 0 , np.zeros([17-j,9]) , axis=0)#adding padding\n",
    "            #print(x_vec)\n",
    "            #print(x_vec.shape)\n",
    "        else:\n",
    "            #print(j)\n",
    "            x_vec=thisSSTuple[0][j-17:j+1,:]\n",
    "            #if(j==18):\n",
    "            #    print(x_vec)\n",
    "            #print(x_vec.shape)\n",
    "        y_vec=thisSSTuple[1][j,:]\n",
    "        #x_vec=tf.convert_to_tensor(x_vec, dtype=np.float32)\n",
    "        #y_vec=tf.convert_to_tensor(y_vec, dtype=np.float32)\n",
    "        ssKmersData.append((x_vec,y_vec))\n",
    "'''\n",
    "'''\n",
    "for tup in angleKmersData:\n",
    "    print(str(tup[0].shape)+\" = \"+str(tup[1].shape))\n",
    "for tup in ssKmersData:\n",
    "    print(str(tup[0].shape)+\" = \"+str(tup[1].shape))\n",
    "'''\n",
    "#notice that this cell has no error\n",
    "print('complete without error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42140, 2)\n",
      "(42140, 35, 9)\n",
      "complete without error\n"
     ]
    }
   ],
   "source": [
    "#for feeding into the model, it has to be converted from list of 2D array to a 3D array\n",
    "#for angle\n",
    "from math import floor\n",
    "from random import random\n",
    "Xa=list()\n",
    "Ya=list()\n",
    "\n",
    "Xatest=list()\n",
    "Yatest=list()\n",
    "#for secondary structure\n",
    "Xs=list()\n",
    "Ys=list()\n",
    "\n",
    "Xstest=list()\n",
    "Ystest=list()\n",
    "for item in angleKmersData:\n",
    "    splitting=floor(random()*10)\n",
    "    if(splitting>7):\n",
    "        Xatest.append(item[0])\n",
    "        Yatest.append(item[1])\n",
    "    else:\n",
    "        Xa.append(item[0])\n",
    "        Ya.append(item[1])\n",
    "for item in ssKmersData:\n",
    "    splitting=floor(random()*10)\n",
    "    if(splitting>7):\n",
    "        Xstest.append(item[0])\n",
    "        Ystest.append(item[1])\n",
    "    else:\n",
    "        Xs.append(item[0])\n",
    "        Ys.append(item[1])\n",
    "\n",
    "# checking\n",
    "#for i in range(len(Xa)):\n",
    "#\tprint(Xa[i], Ya[i])\n",
    "Xa=np.array(Xa) #[samples=S timestamp=18 features=9]\n",
    "Ya=np.array(Ya) #[sample=S features=2]\n",
    "Xs=np.array(Xs)\n",
    "Ys=np.array(Ys)\n",
    "\n",
    "Xatest=np.array(Xatest) #[samples=S timestamp=18 features=9]\n",
    "Yatest=np.array(Yatest) #[sample=S features=2]\n",
    "Xstest=np.array(Xstest)\n",
    "Ystest=np.array(Ystest)\n",
    "\n",
    "#print(Xa.shape)\n",
    "#Xa=Xa.reshape((Xa.shape[0],Xa.shape[1],9))\n",
    "print(Ya.shape)\n",
    "print(Xa.shape)\n",
    "\n",
    "#notice that this cell has no error\n",
    "print('complete without error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete without error\n"
     ]
    }
   ],
   "source": [
    "#import all things needed for tensorflow LSTM network\n",
    "#this is for predicting the next number\n",
    "from tensorflow.keras.models import Sequential #Sequential model\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Flatten #CNN\n",
    "from tensorflow.keras.layers import TimeDistributed #CNN\n",
    "from tensorflow.keras.layers import Conv1D       #CNN\n",
    "from tensorflow.keras.layers import MaxPooling1D #CNN\n",
    "\n",
    "#notice that this cell has no error\n",
    "print('complete without error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Edward\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Edward\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Edward\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Edward\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 42145 samples, validate on 10449 samples\n",
      "Epoch 1/100\n",
      "42145/42145 [==============================] - 17s 399us/sample - loss: 1.3730 - acc: 0.3721 - val_loss: 1.3620 - val_acc: 0.3936\n",
      "Epoch 2/100\n",
      "42145/42145 [==============================] - 14s 337us/sample - loss: 1.3175 - acc: 0.3891 - val_loss: 1.2939 - val_acc: 0.4091\n",
      "Epoch 3/100\n",
      "42145/42145 [==============================] - 14s 334us/sample - loss: 1.2865 - acc: 0.4102 - val_loss: 1.2773 - val_acc: 0.4265\n",
      "Epoch 4/100\n",
      "42145/42145 [==============================] - 14s 339us/sample - loss: 1.2632 - acc: 0.4247 - val_loss: 1.2511 - val_acc: 0.4403\n",
      "Epoch 5/100\n",
      "42145/42145 [==============================] - 14s 336us/sample - loss: 1.2384 - acc: 0.4415 - val_loss: 1.2346 - val_acc: 0.4404\n",
      "Epoch 6/100\n",
      "42145/42145 [==============================] - 14s 337us/sample - loss: 1.2170 - acc: 0.4548 - val_loss: 1.2160 - val_acc: 0.4598\n",
      "Epoch 7/100\n",
      "42145/42145 [==============================] - 14s 335us/sample - loss: 1.2013 - acc: 0.4612 - val_loss: 1.2411 - val_acc: 0.4600\n",
      "Epoch 8/100\n",
      "42145/42145 [==============================] - 14s 341us/sample - loss: 1.1876 - acc: 0.4707 - val_loss: 1.2216 - val_acc: 0.4568\n",
      "Epoch 9/100\n",
      "42145/42145 [==============================] - 14s 337us/sample - loss: 1.1681 - acc: 0.4833 - val_loss: 1.2759 - val_acc: 0.4087\n",
      "Epoch 10/100\n",
      "42145/42145 [==============================] - 14s 341us/sample - loss: 1.1529 - acc: 0.4872 - val_loss: 1.1792 - val_acc: 0.4759\n",
      "Epoch 11/100\n",
      "42145/42145 [==============================] - 14s 340us/sample - loss: 1.1421 - acc: 0.4971 - val_loss: 1.1410 - val_acc: 0.4964\n",
      "Epoch 12/100\n",
      "42145/42145 [==============================] - 15s 346us/sample - loss: 1.1274 - acc: 0.5055 - val_loss: 1.1783 - val_acc: 0.4807\n",
      "Epoch 13/100\n",
      "42145/42145 [==============================] - 15s 356us/sample - loss: 1.1048 - acc: 0.5208 - val_loss: 1.1627 - val_acc: 0.4775\n",
      "Epoch 14/100\n",
      "42145/42145 [==============================] - 15s 345us/sample - loss: 1.0873 - acc: 0.5268 - val_loss: 1.2406 - val_acc: 0.4456\n",
      "Epoch 15/100\n",
      "42145/42145 [==============================] - 14s 333us/sample - loss: 1.0719 - acc: 0.5359 - val_loss: 1.1165 - val_acc: 0.5173\n",
      "Epoch 16/100\n",
      "42145/42145 [==============================] - 14s 338us/sample - loss: 1.0436 - acc: 0.5511 - val_loss: 1.1578 - val_acc: 0.4933\n",
      "Epoch 17/100\n",
      "42145/42145 [==============================] - 14s 335us/sample - loss: 1.0186 - acc: 0.5641 - val_loss: 1.1403 - val_acc: 0.5112\n",
      "Epoch 18/100\n",
      "42145/42145 [==============================] - 14s 333us/sample - loss: 0.9969 - acc: 0.5728 - val_loss: 1.0918 - val_acc: 0.5274\n",
      "Epoch 19/100\n",
      "42145/42145 [==============================] - 14s 339us/sample - loss: 0.9636 - acc: 0.5887 - val_loss: 1.1324 - val_acc: 0.4974\n",
      "Epoch 20/100\n",
      "42145/42145 [==============================] - 14s 339us/sample - loss: 0.9323 - acc: 0.6051 - val_loss: 1.0711 - val_acc: 0.5457\n",
      "Epoch 21/100\n",
      "42145/42145 [==============================] - 14s 337us/sample - loss: 0.8989 - acc: 0.6207 - val_loss: 1.1245 - val_acc: 0.5275\n",
      "Epoch 22/100\n",
      "42145/42145 [==============================] - 14s 338us/sample - loss: 0.8660 - acc: 0.6359 - val_loss: 1.0485 - val_acc: 0.5509\n",
      "Epoch 23/100\n",
      "42145/42145 [==============================] - 14s 343us/sample - loss: 0.8339 - acc: 0.6503 - val_loss: 1.0815 - val_acc: 0.5575\n",
      "Epoch 24/100\n",
      "42145/42145 [==============================] - 14s 338us/sample - loss: 0.8013 - acc: 0.6644 - val_loss: 1.0375 - val_acc: 0.5663\n",
      "Epoch 25/100\n",
      "42145/42145 [==============================] - 14s 338us/sample - loss: 0.7696 - acc: 0.6796 - val_loss: 1.0219 - val_acc: 0.5646\n",
      "Epoch 26/100\n",
      "42145/42145 [==============================] - 14s 343us/sample - loss: 0.7402 - acc: 0.6934 - val_loss: 1.0472 - val_acc: 0.5765\n",
      "Epoch 27/100\n",
      "42145/42145 [==============================] - 14s 341us/sample - loss: 0.7115 - acc: 0.7031 - val_loss: 0.9729 - val_acc: 0.5962\n",
      "Epoch 28/100\n",
      "42145/42145 [==============================] - 14s 338us/sample - loss: 0.6821 - acc: 0.7163 - val_loss: 1.0287 - val_acc: 0.5777\n",
      "Epoch 29/100\n",
      "42145/42145 [==============================] - 14s 335us/sample - loss: 0.6659 - acc: 0.7248 - val_loss: 1.0584 - val_acc: 0.5779\n",
      "Epoch 30/100\n",
      "42145/42145 [==============================] - 14s 338us/sample - loss: 0.6375 - acc: 0.7353 - val_loss: 0.9826 - val_acc: 0.6107\n",
      "Epoch 31/100\n",
      "42145/42145 [==============================] - 14s 342us/sample - loss: 0.6086 - acc: 0.7494 - val_loss: 0.9967 - val_acc: 0.5957\n",
      "Epoch 32/100\n",
      "42145/42145 [==============================] - 14s 338us/sample - loss: 0.5877 - acc: 0.7572 - val_loss: 1.0346 - val_acc: 0.5891\n",
      "Epoch 33/100\n",
      "42145/42145 [==============================] - 14s 337us/sample - loss: 0.5661 - acc: 0.7635 - val_loss: 0.9945 - val_acc: 0.6048\n",
      "Epoch 34/100\n",
      "42145/42145 [==============================] - 14s 339us/sample - loss: 0.5514 - acc: 0.7722 - val_loss: 0.9890 - val_acc: 0.6022\n",
      "Epoch 35/100\n",
      "42145/42145 [==============================] - 14s 338us/sample - loss: 0.5293 - acc: 0.7816 - val_loss: 0.9648 - val_acc: 0.6210\n",
      "Epoch 36/100\n",
      "42145/42145 [==============================] - 14s 342us/sample - loss: 0.5133 - acc: 0.7897 - val_loss: 0.9378 - val_acc: 0.6243\n",
      "Epoch 37/100\n",
      "42145/42145 [==============================] - 15s 346us/sample - loss: 0.4909 - acc: 0.7995 - val_loss: 1.0477 - val_acc: 0.6042\n",
      "Epoch 38/100\n",
      "42145/42145 [==============================] - 14s 343us/sample - loss: 0.4720 - acc: 0.8083 - val_loss: 0.9029 - val_acc: 0.6483\n",
      "Epoch 39/100\n",
      "42145/42145 [==============================] - 14s 336us/sample - loss: 0.4592 - acc: 0.8116 - val_loss: 1.0913 - val_acc: 0.6046\n",
      "Epoch 40/100\n",
      "42145/42145 [==============================] - 14s 337us/sample - loss: 0.4344 - acc: 0.8234 - val_loss: 0.9823 - val_acc: 0.6398\n",
      "Epoch 41/100\n",
      "42145/42145 [==============================] - 14s 337us/sample - loss: 0.4302 - acc: 0.8254 - val_loss: 1.0174 - val_acc: 0.6320\n",
      "Epoch 42/100\n",
      "42145/42145 [==============================] - 14s 338us/sample - loss: 0.4108 - acc: 0.8341 - val_loss: 1.0541 - val_acc: 0.6168\n",
      "Epoch 43/100\n",
      "42145/42145 [==============================] - 14s 338us/sample - loss: 0.3918 - acc: 0.8430 - val_loss: 1.1344 - val_acc: 0.6105\n",
      "Epoch 44/100\n",
      "42145/42145 [==============================] - 14s 341us/sample - loss: 0.3804 - acc: 0.8485 - val_loss: 1.0633 - val_acc: 0.6345\n",
      "Epoch 45/100\n",
      "42145/42145 [==============================] - 14s 333us/sample - loss: 0.3710 - acc: 0.8527 - val_loss: 1.0890 - val_acc: 0.6263\n",
      "Epoch 46/100\n",
      "42145/42145 [==============================] - 14s 332us/sample - loss: 0.3592 - acc: 0.8580 - val_loss: 0.9830 - val_acc: 0.6618\n",
      "Epoch 47/100\n",
      "42145/42145 [==============================] - 14s 341us/sample - loss: 0.3370 - acc: 0.8679 - val_loss: 1.1013 - val_acc: 0.6301\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42145/42145 [==============================] - 14s 338us/sample - loss: 0.3278 - acc: 0.8741 - val_loss: 0.9607 - val_acc: 0.6726\n",
      "Epoch 49/100\n",
      "42145/42145 [==============================] - 14s 336us/sample - loss: 0.3167 - acc: 0.8738 - val_loss: 1.0664 - val_acc: 0.6385\n",
      "Epoch 50/100\n",
      "42145/42145 [==============================] - 14s 342us/sample - loss: 0.2999 - acc: 0.8843 - val_loss: 1.0947 - val_acc: 0.6493\n",
      "Epoch 51/100\n",
      "42145/42145 [==============================] - 14s 337us/sample - loss: 0.2967 - acc: 0.8826 - val_loss: 1.0410 - val_acc: 0.6626\n",
      "Epoch 52/100\n",
      "42145/42145 [==============================] - 14s 343us/sample - loss: 0.2859 - acc: 0.8894 - val_loss: 1.0239 - val_acc: 0.6590\n",
      "Epoch 53/100\n",
      "42145/42145 [==============================] - 14s 336us/sample - loss: 0.2682 - acc: 0.8973 - val_loss: 1.1134 - val_acc: 0.6592\n",
      "Epoch 54/100\n",
      "42145/42145 [==============================] - 15s 352us/sample - loss: 0.2607 - acc: 0.8994 - val_loss: 1.0717 - val_acc: 0.6703\n",
      "Epoch 55/100\n",
      "42145/42145 [==============================] - 16s 375us/sample - loss: 0.2531 - acc: 0.9032 - val_loss: 1.1564 - val_acc: 0.6524\n",
      "Epoch 56/100\n",
      "42145/42145 [==============================] - 15s 353us/sample - loss: 0.2296 - acc: 0.9133 - val_loss: 1.1340 - val_acc: 0.6626\n",
      "Epoch 57/100\n",
      "42145/42145 [==============================] - 14s 339us/sample - loss: 0.2335 - acc: 0.9115 - val_loss: 1.1931 - val_acc: 0.6434\n",
      "Epoch 58/100\n",
      "42145/42145 [==============================] - 14s 340us/sample - loss: 0.2236 - acc: 0.9170 - val_loss: 1.1742 - val_acc: 0.6604\n",
      "Epoch 59/100\n",
      "42145/42145 [==============================] - 14s 342us/sample - loss: 0.2072 - acc: 0.9241 - val_loss: 1.1846 - val_acc: 0.6581\n",
      "Epoch 60/100\n",
      "42145/42145 [==============================] - 15s 358us/sample - loss: 0.2027 - acc: 0.9270 - val_loss: 1.1452 - val_acc: 0.6736\n",
      "Epoch 61/100\n",
      "42145/42145 [==============================] - 82s 2ms/sample - loss: 0.1891 - acc: 0.9318 - val_loss: 1.2823 - val_acc: 0.6460\n",
      "Epoch 62/100\n",
      "42145/42145 [==============================] - 15s 346us/sample - loss: 0.1881 - acc: 0.9326 - val_loss: 1.2171 - val_acc: 0.6687\n",
      "Epoch 63/100\n",
      "42145/42145 [==============================] - 14s 337us/sample - loss: 0.1776 - acc: 0.9375 - val_loss: 1.1839 - val_acc: 0.6765\n",
      "Epoch 64/100\n",
      "42145/42145 [==============================] - 14s 337us/sample - loss: 0.1711 - acc: 0.9386 - val_loss: 1.2181 - val_acc: 0.6746\n",
      "Epoch 65/100\n",
      "42145/42145 [==============================] - 14s 342us/sample - loss: 0.1643 - acc: 0.9416 - val_loss: 1.2634 - val_acc: 0.6603\n",
      "Epoch 66/100\n",
      "42145/42145 [==============================] - 14s 334us/sample - loss: 0.1582 - acc: 0.9439 - val_loss: 1.4985 - val_acc: 0.6243\n",
      "Epoch 67/100\n",
      "42145/42145 [==============================] - 14s 341us/sample - loss: 0.1516 - acc: 0.9494 - val_loss: 1.2666 - val_acc: 0.6723\n",
      "Epoch 68/100\n",
      "42145/42145 [==============================] - 14s 344us/sample - loss: 0.1457 - acc: 0.9492 - val_loss: 1.4682 - val_acc: 0.6498\n",
      "Epoch 69/100\n",
      "42145/42145 [==============================] - 14s 338us/sample - loss: 0.1447 - acc: 0.9516 - val_loss: 1.2648 - val_acc: 0.6827\n",
      "Epoch 70/100\n",
      "42145/42145 [==============================] - 14s 339us/sample - loss: 0.1362 - acc: 0.9530 - val_loss: 1.3625 - val_acc: 0.6656\n",
      "Epoch 71/100\n",
      "42145/42145 [==============================] - 14s 341us/sample - loss: 0.1358 - acc: 0.9544 - val_loss: 1.2319 - val_acc: 0.6844\n",
      "Epoch 72/100\n",
      "42145/42145 [==============================] - 14s 336us/sample - loss: 0.1212 - acc: 0.9591 - val_loss: 1.4332 - val_acc: 0.6475\n",
      "Epoch 73/100\n",
      "42145/42145 [==============================] - 14s 340us/sample - loss: 0.1269 - acc: 0.9572 - val_loss: 1.4858 - val_acc: 0.6556\n",
      "Epoch 74/100\n",
      "42145/42145 [==============================] - 15s 347us/sample - loss: 0.1163 - acc: 0.9634 - val_loss: 1.3755 - val_acc: 0.6716\n",
      "Epoch 75/100\n",
      "42145/42145 [==============================] - 14s 335us/sample - loss: 0.1145 - acc: 0.9627 - val_loss: 1.3255 - val_acc: 0.6797\n",
      "Epoch 76/100\n",
      "42145/42145 [==============================] - 14s 337us/sample - loss: 0.1122 - acc: 0.9638 - val_loss: 1.4069 - val_acc: 0.6787\n",
      "Epoch 77/100\n",
      "42145/42145 [==============================] - 15s 349us/sample - loss: 0.1144 - acc: 0.9640 - val_loss: 1.4419 - val_acc: 0.6638\n",
      "Epoch 78/100\n",
      "42145/42145 [==============================] - 15s 347us/sample - loss: 0.1084 - acc: 0.9650 - val_loss: 1.4925 - val_acc: 0.6622\n",
      "Epoch 79/100\n",
      "42145/42145 [==============================] - 15s 347us/sample - loss: 0.0955 - acc: 0.9711 - val_loss: 1.4285 - val_acc: 0.6742\n",
      "Epoch 80/100\n",
      "42145/42145 [==============================] - 14s 342us/sample - loss: 0.1004 - acc: 0.9673 - val_loss: 1.5524 - val_acc: 0.6631\n",
      "Epoch 81/100\n",
      "42145/42145 [==============================] - 14s 335us/sample - loss: 0.0956 - acc: 0.9699 - val_loss: 1.5708 - val_acc: 0.6586\n",
      "Epoch 82/100\n",
      "42145/42145 [==============================] - 14s 335us/sample - loss: 0.0967 - acc: 0.9692 - val_loss: 1.4672 - val_acc: 0.6781\n",
      "Epoch 83/100\n",
      "42145/42145 [==============================] - 14s 339us/sample - loss: 0.0866 - acc: 0.9737 - val_loss: 1.5354 - val_acc: 0.6713\n",
      "Epoch 84/100\n",
      "42145/42145 [==============================] - 14s 338us/sample - loss: 0.0918 - acc: 0.9713 - val_loss: 1.5485 - val_acc: 0.6696\n",
      "Epoch 85/100\n",
      "42145/42145 [==============================] - 14s 343us/sample - loss: 0.0900 - acc: 0.9715 - val_loss: 1.4895 - val_acc: 0.6805\n",
      "Epoch 86/100\n",
      "42145/42145 [==============================] - 14s 338us/sample - loss: 0.0773 - acc: 0.9763 - val_loss: 1.6296 - val_acc: 0.6534\n",
      "Epoch 87/100\n",
      "42145/42145 [==============================] - 14s 340us/sample - loss: 0.0772 - acc: 0.9765 - val_loss: 1.5772 - val_acc: 0.6615\n",
      "Epoch 88/100\n",
      "42145/42145 [==============================] - 14s 339us/sample - loss: 0.0866 - acc: 0.9733 - val_loss: 1.6126 - val_acc: 0.6654\n",
      "Epoch 89/100\n",
      "42145/42145 [==============================] - 15s 348us/sample - loss: 0.0888 - acc: 0.9728 - val_loss: 1.5203 - val_acc: 0.6796\n",
      "Epoch 90/100\n",
      "42145/42145 [==============================] - 14s 337us/sample - loss: 0.0689 - acc: 0.9798 - val_loss: 1.5644 - val_acc: 0.6807\n",
      "Epoch 91/100\n",
      "42145/42145 [==============================] - 14s 338us/sample - loss: 0.0787 - acc: 0.9752 - val_loss: 1.5821 - val_acc: 0.6777\n",
      "Epoch 92/100\n",
      "42145/42145 [==============================] - 14s 339us/sample - loss: 0.0777 - acc: 0.9748 - val_loss: 1.6409 - val_acc: 0.6639\n",
      "Epoch 93/100\n",
      "42145/42145 [==============================] - 14s 340us/sample - loss: 0.0718 - acc: 0.9777 - val_loss: 1.6150 - val_acc: 0.6841\n",
      "Epoch 94/100\n",
      "42145/42145 [==============================] - 14s 340us/sample - loss: 0.0649 - acc: 0.9805 - val_loss: 1.5640 - val_acc: 0.6832\n",
      "Epoch 95/100\n",
      "42145/42145 [==============================] - 15s 344us/sample - loss: 0.0664 - acc: 0.9793 - val_loss: 1.6587 - val_acc: 0.6749\n",
      "Epoch 96/100\n",
      "42145/42145 [==============================] - 14s 339us/sample - loss: 0.0784 - acc: 0.9750 - val_loss: 1.5471 - val_acc: 0.6884\n",
      "Epoch 97/100\n",
      "42145/42145 [==============================] - 14s 339us/sample - loss: 0.0681 - acc: 0.9786 - val_loss: 1.6160 - val_acc: 0.6810\n",
      "Epoch 98/100\n",
      "42145/42145 [==============================] - 14s 340us/sample - loss: 0.0665 - acc: 0.9793 - val_loss: 1.5707 - val_acc: 0.6896\n",
      "Epoch 99/100\n",
      "42145/42145 [==============================] - 14s 344us/sample - loss: 0.0571 - acc: 0.9831 - val_loss: 2.0084 - val_acc: 0.6324\n",
      "Epoch 100/100\n",
      "42145/42145 [==============================] - 14s 337us/sample - loss: 0.0670 - acc: 0.9801 - val_loss: 1.5978 - val_acc: 0.6926\n",
      "complete without error\n"
     ]
    }
   ],
   "source": [
    "##setting up callback for tensor board\n",
    "# Load the TensorBoard notebook extension\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "\n",
    "import datetime\n",
    "#log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "##saving checkpoint\n",
    "model_checkpoint_callback1 = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./saved_model/checkpoint/max',\n",
    "    save_weights_only=False,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    "    \n",
    ")\n",
    "model_checkpoint_callback2 = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./saved_model/checkpoint/e50',\n",
    "    save_weights_only=False,\n",
    "    save_freq=50,\n",
    "    save_best_only=False,\n",
    ")\n",
    "\n",
    "##setting up model\n",
    "\n",
    "# for CNN-LSTM reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "# if not using CNN, just comment this line\n",
    "#Xa=Xa.reshape(Xa.shape[0],Xa.shape[1],Xa.shape[2],1)\n",
    "\n",
    "#model\n",
    "model = Sequential()\n",
    "#model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, 9,1)))\n",
    "#model.add(TimeDistributed(MaxPooling1D(pool_size=9)))\n",
    "#model.add(TimeDistributed(Flatten()))\n",
    "model.add(Bidirectional(LSTM(100, activation='tanh',return_sequences=True, recurrent_activation='sigmoid', use_bias=True , input_shape=(35,9))))\n",
    "#model.add(Bidirectional(LSTM(200, activation='relu',return_sequences=True, recurrent_activation='sigmoid', use_bias=True )))\n",
    "model.add(Bidirectional(LSTM(100, activation='tanh',return_sequences=True, recurrent_activation='sigmoid', use_bias=True )))\n",
    "#model.add(Bidirectional(LSTM(150, activation='tanh',return_sequences=True, recurrent_activation='sigmoid', use_bias=True )))\n",
    "#model.add(Bidirectional(LSTM(256, activation='relu',return_sequences=True, recurrent_activation='sigmoid', use_bias=True )))\n",
    "#model.add(Bidirectional(LSTM(256, activation='tanh',return_sequences=True, recurrent_activation='sigmoid', use_bias=True )))\n",
    "#model.add(Bidirectional(LSTM(256, activation='relu',return_sequences=True, recurrent_activation='sigmoid', use_bias=True )))\n",
    "#model.add(Bidirectional(LSTM(100, activation='tanh',return_sequences=True, recurrent_activation='sigmoid', use_bias=True )))\n",
    "model.add(Bidirectional(LSTM(100, activation='tanh',  recurrent_activation='sigmoid', use_bias=True )))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#fitting the model\n",
    "model.fit(x=Xs,\n",
    "          y=Ys,\n",
    "          batch_size=1000,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          callbacks=[#tensorboard_callback,\n",
    "              model_checkpoint_callback1,\n",
    "              model_checkpoint_callback2 ],\n",
    "          validation_data=(Xstest,Ystest)\n",
    "         )\n",
    "#starting tensorboard\n",
    "\n",
    "model.save('./saved_model/ssModel')\n",
    "\n",
    "#notice that this cell has no error\n",
    "print('complete without error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 292ms/sample\n",
      "[[4.1650012e-05 3.0309115e-09 2.7856034e-10 9.9995840e-01]]\n"
     ]
    }
   ],
   "source": [
    "### print('training done')\n",
    "#demonstrate prediction\n",
    "x_input = Xa[0,:,:]\n",
    "x_input=x_input.reshape((1,35,9))\n",
    "yhat = model.predict(x_input,verbose=1)\n",
    "print(yhat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
